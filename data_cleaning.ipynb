{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataframe(df, registry, start, end, verbose=False):\n",
    "\n",
    "    registry['DateStop'] = pd.to_datetime(registry['DateStop'])\n",
    "    registry = registry[registry['Pollutant'] == pollutant]\n",
    "    active = registry[(pd.isna(registry.DateStop)) | (registry.DateStop > pd.to_datetime(end))]\n",
    "\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "    data = df[(df.Date > pd.to_datetime(start)) & (df.Date < pd.to_datetime(end))]\n",
    "    data = data.groupby('IDStation', as_index=False).apply(lambda g: g.mean(skipna=True))\n",
    "    data['IDStation'] = data['IDStation'].astype(int)\n",
    "\n",
    "\n",
    "    active = registry[(pd.isna(registry.DateStop)) | (registry.DateStop > pd.to_datetime(end))]\n",
    "\n",
    "    clean_df = pd.merge(data, active[['IDStation', 'Latitude', 'Longitude', 'Altitude']], on='IDStation', how='inner')\n",
    "\n",
    "    if verbose:\n",
    "        print(clean_df.shape)\n",
    "        print(clean_df.info())        \n",
    "\n",
    "    return clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_shift(df, feature, verbose=False, output=None):\n",
    "\n",
    "    min_value = df[feature].min()\n",
    "    max_value = df[feature].max()\n",
    "\n",
    "    if verbose:\n",
    "        print('\\n' + feature)\n",
    "        print('Min: {}, Max: {}'.format(min_value, max_value))\n",
    "    \n",
    "    if output:\n",
    "        output.write('\\n' + feature + '\\n')\n",
    "        output.write('Min: {}, Max: {}\\n'.format(min_value, max_value))\n",
    "    \n",
    "    normalized = df[feature].copy()\n",
    "\n",
    "    if min_value < 0:\n",
    "\n",
    "        normalized += np.abs(min_value)\n",
    "        max_value += np.abs(min_value)\n",
    "\n",
    "        if verbose: \n",
    "            print('Some negative values found, with ratio: {}\\n'.format(round(100*(np.abs(min_value) / max_value), 2)))\n",
    "\n",
    "        if output:\n",
    "            output.write('Some negative values found, with ratio: {}\\n'.format(round(100*(np.abs(min_value) / max_value), 2)))\n",
    "    else:\n",
    "\n",
    "        if verbose: print('Only positive values found.\\n')\n",
    "\n",
    "        if output:  output.write('Only positive values found.\\n')\n",
    "  \n",
    "    df[feature + '_Norm'] = normalized / max_value \n",
    "\n",
    "    if verbose: print(df.head(3))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df, feature1, feature2, verbose=False, output=None):\n",
    "\n",
    "    min_value_1 = df[feature1].min()\n",
    "    max_value_1 = df[feature1].max()\n",
    "    min_value_2 = df[feature2].min()\n",
    "    max_value_2 = df[feature2].max()\n",
    "\n",
    "    max_value = max_value_1 if max_value_1 > max_value_2 else max_value_2\n",
    "    min_value = min_value_1 if min_value_1 < min_value_2 else min_value_2\n",
    "\n",
    "    if verbose:\n",
    "        print('\\n' + feature1 + '\\n')\n",
    "        print('Min: {}, Max: {}\\n'.format(min_value_1, max_value_1))\n",
    "\n",
    "        print('\\n' + feature2 + '\\n')\n",
    "        print('Min: {}, Max: {}\\n'.format(min_value_2, max_value_2))\n",
    "    \n",
    "    if output:\n",
    "        output.write('\\n' + feature1 + '\\n')\n",
    "        output.write('Min: {}, Max: {}\\n'.format(min_value_1, max_value_1))\n",
    "\n",
    "        output.write('\\n' + feature2 + '\\n')\n",
    "        output.write('Min: {}, Max: {}\\n'.format(min_value_2, max_value_2))\n",
    "    \n",
    "    normalized = df[feature2].copy()\n",
    "    \n",
    "    df[feature1 + '_Norm'] = df[feature1] / max_value     \n",
    " \n",
    "    df[feature2 + '_Norm'] = normalized / max_value \n",
    "\n",
    "    if verbose: print(df.head(3))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pollutants = ['NO2', 'NOx', 'PM2.5', 'PM10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registry = pd.read_csv('./data/registry.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/report.txt', 'w') as f:\n",
    "\n",
    "    for pollutant in pollutants:\n",
    "\n",
    "        df = pd.read_csv('./data/raw/{}_sit_monthly.csv'.format(pollutant)).drop('Unnamed: 0', axis=1)\n",
    "\n",
    "        clean_df_2019 = clean_dataframe(df, registry, 'March 2019', 'July 2019', verbose=False)\n",
    "\n",
    "        if download: clean_df_2019.to_csv('./data/2019/{}_2019.csv'.format(pollutant))\n",
    "\n",
    "        clean_df_2020 = clean_dataframe(df, registry, 'March 2020', 'July 2020', verbose=False)\n",
    "\n",
    "        if download: clean_df_2020.to_csv('./data/2020/{}_2020.csv'.format(pollutant))\n",
    "\n",
    "        df = pd.merge(clean_df_2019, clean_df_2020, on=['IDStation', 'Latitude', 'Longitude', 'Altitude'], suffixes=['_2019', '_2020'])\n",
    "\n",
    "        df['{}_Delta'.format(pollutant)] = df[pollutant+ '_2019'] - df[pollutant + '_2020']\n",
    "\n",
    "        df = df[['IDStation', pollutant+ '_2019', pollutant+ '_2020', pollutant+ '_Delta', 'Latitude', 'Longitude']]\n",
    "\n",
    "        df = df.dropna()  \n",
    "\n",
    "        df['{}_Abs'.format(pollutant)] = np.abs(df['{}_Delta'.format(pollutant)])\n",
    "\n",
    "        df = normalize_and_shift(df, pollutant + '_Delta', verbose=True, output=f)\n",
    "\n",
    "        df = normalize(df, pollutant + '_2019', pollutant + '_2020', verbose=True, output=f)\n",
    "        \n",
    "        if download: df.to_csv('./data/{}.csv'.format(pollutant))        "
   ]
  }
 ]
}